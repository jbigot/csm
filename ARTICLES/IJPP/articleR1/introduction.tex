As the computation power of modern high performance architectures increases, their heterogeneity and complexity also become more important. For example, the current fastest supercomputer Tianhe-2~\footnote{\url{www.top500.org}} is composed of multi-cores processors and accelerators, and is able to reach a theoretical peak performance of about thirty peta-flops (floating-point operations per second). However, to be able to use such machines, multiple programming models, such as MPI (Message Passing Interface), OpenMP, CUDA, etc., and multiple optimization techniques, such as cache optimization, have to be combined. Moreover, current architectures evolution seems to indicate that heterogeneity and complexity in HPC will continue to grow in the future.

One of the big challenges to be able to use those upcoming Exascale computers is to propose programming models that give access to high performance computing (HPC) to many scientists and not only to a few HPC specialists~\cite{ETP4HPC2013}. Actually, applications that run on supercomputers and need such computation power (\textit{e.g.} physics, weather or genomic) are typically not implemented by HPC specialists but by domain scientists.

%\JB{pourquoi tu parles de taches ?}
%One possible runtime execution model for HPC is based on dynamic scheduling of task graphs combined with message passing~\cite{Gautier:2013:XRS:2510661.2511383,Augonnet2011,wu:hal-01078359}.
%These models increase code portability and enable users to reach interesting performance on heterogeneous architectures.
%\JB{j'enleverais ce qui est au dessus et je commencerait tout de suite avec "OpenMP c'est compliqu√©"}
%General purpose parallel languages, such as OpenMP~\cite{660313} and OpenCL~\cite{Stone:2010:OPP:622179.1803953} start to include these concepts.
Many general purpose languages and frameworks have improved the simplicity of writing parallel codes. For example PGAS models~\cite{Nieplocha:2006:AAP:1125980.1125985} or task-based frameworks, such as OpenMP~\cite{660313}, Legion~\cite{bauer:legion:sc:2012} or StarPU~\cite{Augonnet2011}, partially hide intricate details of parallelism to the user. For non-expert users however, these languages and frameworks are still difficult to use. Moreover, tuning an application for a given architecture is still very complex to achieve with these solutions.
An interesting approach that combines simplicity of use, due to a high abstraction level, with efficient execution are domain specific languages (DSL) and domain specific frameworks (DSF).
These solutions are specific to a given domain and propose a grammar or an API which is easy to understand for specialists of this domain.
Moreover, knowledge about the targeted domain can be embedded in the compiler that can thus automatically apply parallelization and optimization techniques to produce high performance code.
Domain specific solutions are therefore able to separate end-user concerns from HPC concerns which is a requirement to make HPC accessible to a wider audience.

Many domain specific languages and frameworks have been proposed. Each one claims to handle a distinct specific optimization or use case.
Each solution is however typically re-implemented from scratch.
In this paper, we claim that the sharing of common building blocks when designing DSLs or DSFs would increases re-use, flexibility and maintainability in their implementation.
It would also ease the creation of approaches and applications combining multiple DSLs and DSFs.

For example, some of the approaches to numerically solve partial differential equations (PDEs) lead to \emph{stencil computations} where the values associated to one point in space at a given time are computed from the values at the previous time at the exact same location together with a few neighbor locations.
Many DSLs have been proposed for stencil computations~\cite{spaaTangCKLL11,citeulike12258902,Ragan-Kelley:2013:HLC:2491956.2462176,DeVito:2011:LDS:2063384.2063396,Camier:2015:IPP:2820083.2820107} as detailed in Section~\ref{sect:rel}.
Many of them use the same kind of parallelization, data structures or optimization techniques, however each one has been built from scratch. 

We propose the Multi-Stencil Framework (MSF) that is built upon a meta-formalism of multi-stencil simulations. MSF produces a parallel orchestration of a multi-stencil program without being aware of the underlying implementation choices (\eg distributed data structures, task scheduler etc.). Thanks to this meta-formalism MSF is able to easily switch from one parallelization technique to another and from one optimization to another. Moreover, as MSF is independent from implementation details, MSF can easily choose one back-end or another, thus easing code reuse of existing solutions.
To ease composition of existing solutions, MSF is based on component-based programming~\cite{Szyperski:2002:CSB:515228}, where applications are defined as an assembly of building blocks, or components.

After a short overview of the Multi-Stencil Framework given in Section~\ref{sect:msf}, the paper is organized as follows. The meta-formalism of a multi-stencil program is presented in Section~\ref{sect:formalism}; from this formalism are built both a light and descriptive domain specific language, namely MSL, as well as a generic component assembly of the application both described in Section~\ref{sect:msl}; the compiler of the framework is described in Section~\ref{sect:parallelism}; finally a performance evaluation is detailed in Section~\ref{sect:eval} .

%as far as we know, only a few of them have been able to reuse work already done by another language~\cite{Sujeeth:2013:CRC:2524984.2524988}. In other words, software engineering properties have to be integrated into DSL conception, such that a new DSL can be seen as a composition of parallelization, optimizations or even languages semantics already proposed by others.
%For example, to numerically solve a set of partial differential equations (PDEs), iterative methods are frequently used to approximate the exact solution through a discretized phenomena. A very well known and usual way to discretize PDEs is to transform them to explicit numerical schemes, also often called \emph{stencils}. Many DSLs have been proposed for stencil computations~\cite{spaaTangCKLL11,citeulike12258902,Ragan-Kelley:2013:HLC:2491956.2462176,DeVito:2011:LDS:2063384.2063396,Camier:2015:IPP:2820083.2820107}, as it will be detailed in Section~\ref{sect:rel}. Many of them use same kind of parallelization, data structures or optimizations, however each one has been built from scratch to deal with another additionnal specific case.
%We present the Multi-Stencil Language (MSL) DSL, also for stencil-based numerical simulations. MSL is a language with a light grammar to describe a numerical simulation without implementation details. From the description, the compiler has enough information to extract and build an empty parallel pattern of the simulation, which can be filled, in a second step, by implementation concerns. The parallel pattern generated by the language is able to use different existing languages and libraries as it is independent from implementation choices. Moreover, the parallelization performed by the language is large enough to be compatible with many architectures and back-end languages. Contributions presented in this paper are : the computational model of a multi-stencil program and its parallelization formalism; the MSL grammar and its compiler; a back-end implementation and its performance evaluation onto a real case numerical simulation up to 16.384 cores.

%Section~\ref{sect:rel} introduces the related work on DSLs for stencils. Section~\ref{sect:formalism} formally explains the targetted domain and its computational model. From this model can be extracted the grammar of MSL in Section~\ref{sect:msl}. Section~\ref{sect:parallelism} shows how parallelism can be extracted from this light grammar of MSL. Sections~\ref{sect:msp} and~\ref{sect:comp} detail choices that have been done in this paper to evaluate MSL, and Section~\ref{sect:eval} shows performance results of the language. Finally, Section~\ref{sect:concl} concludes and proposes perspectives on this work.