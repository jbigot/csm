% Multi-stencil mesh-based numerical simulation can be parallelized in various ways and is an interesting kind of application to take advantage of modern heterogeneous HPC architectures, mixing clusters, multi-cores CPUs, vectorization units, GPGPU and many-core accelerators.

%------------------------------
\subsection{Data parallelism}
\label{sect:dataparal}
In a data parallelization technique, the idea is to split the data on which the program is computed into balanced sub-parts, one for each available resource. The same sequential program can afterwards be applied on each sub-part simultaneously, with some additioinal synchronizations between resources to update the data not computed locally, and thus to guarantee a correct result.

More formally, the data parallelization of a multi-stencil program $\mathcal{MSP}(T,\mathcal{M},\mathcal{E},\mathcal{D},\Delta, \mathcal{S},\Gamma)$ consists in, first, a partitioning of the mesh $\mathcal{M}$ in $p$ balanced sub-meshes (for $p$ resources) $\mathcal{M}=\{\mathcal{M}_0,\dots,\mathcal{M}_{p-1}\}$. This step can be performed by an external graph partitionner~\cite{} and is not adressed by this paper. As a data is mapped onto the mesh, the set of data $\Delta$ is partitionned the same way than the mesh in $\Delta=\{\Delta_0,\dots,\Delta_{p-1}\}$. The second step of the parallelization is to identify in $\Gamma$ the needed synchronizations between resources to update data, and thus to build a new ordered list of computations $\Gamma_{sync}$.

\begin{mydef}
\textit{
For $n$ the number of computations in $\Gamma$, and for $i,j$ such that $i<j<n$, a \textit{synchronisation} is needed between $k_i$ and $k_j$, denoted $k_i \pprec k_j$, if $\exists (r,n) \in R_j$ with $n\neq identity$ ($k_j$ is a stencil computation), and such that $\{w_i\} \subset R_j$. Moreover, the data to update is $\{w_i\} \cap R_j = \{w_i$\}.}
\end{mydef}

Actually, a synchronization can only be needed by the data read by a stencil computation (not local), and only if this data has been modified before, which means that it has been written before. This synchronization is needed because a neighborhood function $n \in \mathcal{N}$ of a stencil computation involves values computed on different resources.

\begin{mydef}
\textit{A synchronization between two computations $k_i \pprec k_j$ is defined as a specific computation $sync(R,w,exp,D)$ where $R=\{w_i\}$, $w=w_i$, $exp=identity$ and $D=\emptyset$.}
\end{mydef}

\begin{mydef}
If a synchronization is needed before $k_j$ (on the data $w_i$), $k_j$ is replaced in $\Gamma_{sync}$ by the list
\begin{equation*}
\Gamma_{sync} = [sync(\{w_i\},w_i,identity,\emptyset), k_j]
\end{equation*}
\end{mydef}

\begin{mydef}
The concatenation of two ordered lists of respectively $n$ and $m$ computations $l_1=[k_i]_{0 \leq i \leq n-1}$ and $l_2=[c'_i]_{0 \leq i \leq m-1}$ is denoted $l_1 \cdot l_2$ and is equal to a new ordered list $l_3=[c_0,\dots,c_{n-1},c'_0,\dots,c'_{m-1}]$.
\end{mydef}

\begin{mydef}
From the ordered list of computation $\Gamma$, a new ordered list $\Gamma_{sync}$ is obtained from the call $\Gamma_{sync} = F_{sync}(\Gamma,0)$, where $F_{sync}$ is the recursive function defined as
\begin{equation*}
F_{sync}(\Gamma,j) = 
\begin{cases} 	[\Gamma[j]] \cdot F_{sync}(\Gamma,j+1) & \mbox{if }\forall i<j \mbox{, } k_i \not\pprec k_j\\
				[sync(\{w_i\},w_i,identity,\emptyset), k_j] \cdot F_{sync}(\Gamma,j+1) & \forall i<j \text{, and }k_i \pprec k_j\}\\
				[] & \mbox{if }j=|\Gamma|.
\end{cases}
\end{equation*}
\end{mydef}

% The construction of $\Gamma_{data}$ implies that if a synchronization is needed it is always proceeded before the computation wich needs it. One can notice that a combination of synchronizations is possible in some cases, and thus it is possible to synchronize more than one data at a time. %If the number of synchronizations is reduced, final performance of the program will be better. 
% For this reason, we define a reduction which can be applied to $\Gamma_{data}$, and which is performed as a post-transformation. This reduction, could propose better performance depending on the used network speed.

% \begin{myprop}
% Denoting four computations $c_l$, $c_k$, $k_i$ and $k_j$ of $\Gamma$, with $l<k$, $i<j$, and where $c_l \pprec c_k$ and $k_i \pprec k_j$. Then, computations $c_k$ and $k_j$ are tansformed to $c^*_k(c_k,update(w_l))$ and $c^*_j(k_j,update(w_i))$. If $i<k$, a single update call can be performed at $k$ such that $c^*_k(c_k,update(w_l\cup w_i))$, and in this case, the computation $k_j$ is not transformed.
% \end{myprop}

% \begin{proof}
% By definition, the synchronization of $w_i$ can be performed between $k_i$ and $k_j$. As $i<k$ the computation $k_i$ is not performed between $k$ and $j$. As a result, the synchronization of $w_i$ can be performed between $k_i$ and $c_k$.
% \end{proof}

% In other words, for each synchronization in $\Gamma_{data}$, if the computation $k_i$ from which $k_j$ is synchronized occurs before the last synchronization, the two synchronizations can be reduced to one with the union of the data to update.


 The final step of this parallelization is to run $\Gamma_{sync}$ on each resource. Thus, for each resource $0 \leq k \leq p-1$ a multi-stencil program, defined by
\begin{equation}
\mathcal{MSP}_k(T,\mathcal{M}_k,\mathcal{E},\mathcal{D},\Delta_k, \mathcal{S},\Gamma_{sync}),
\end{equation}
is performed.

%We denote this parallelization technique a coarse-grain data parallelization in contrast with the same technique applied to the finer level of a single computation. In this case, for a computation $c(R,w,D,\text{exp})$, the local domain $D$ is partitionned for $p$ resources $\{D_0,\dots,D_{p-1}\}$, and each resource $k$ is responsible for a sub-computation $c_k(R,w,D_k,\text{exp}')$.
%This finer data parallelization technique is not directly adressed by the work presented in this paper, but is exhibited, as it will be explained later. 

%------------------------------
\subsection{Hybrid parallelism}
A task parallelization technique is a technique to transform a program as a dependency graph of different tasks. A dependency graph exhibits parallel tasks, or on the contrary sequential execution of tasks. Such a dependency graph can directly be given to a dynamic scheduler, or can be statically scheduled. In this paper, we introduce task parallelism by building the dependency graph between computations of the sequential list $\Gamma_{sync}$ (which itself take into account data parallelism).

\begin{mydef}
For two computations $k_i(R_i,w_i,\text{exp}_i,D_i)$ and $k_j(R_j,w_j,\text{exp}_j,D_j)$, with $i < j$, it is said that $k_j$ is data dependant from $k_i$, denoted $k_i\prec k_j$, if $\{w_i\} \cap R_j \neq \emptyset$. In this case, $k_i$ has to be computed before $k_j$. The binary relation $k_i\prec k_j$ represents a \textit{dependency}.
\end{mydef}

% \begin{myprop}
% The binary relation $\prec$ is not transitive. 
% \end{myprop}

% \begin{proof}
% Considering three computations $c_0(R_0,w_0,\text{exp}_0)$, $c_1(R_1,w_1,\text{exp}_1)$ and $c_2(R_2,w_2,\text{exp}_2)$, where $\{w_0\}\cap R_1 \neq \emptyset$ and $\{w_1\}\cap R_2 \neq \emptyset$. In this case two dependencies can be extracted $c_0 \prec c_1$ and $c_1 \prec c_2$. However, the dependency $c_0 \prec c_2$ is not true as $\{w_0\}\cap R_2 = \emptyset$.
% \end{proof}

% It has been proved that the binary relation $\prec$ is not transitive. This property is due to the fact that $\prec$ is defined as a data dependency between computations. However, another type of dependency, only due to time, is created from $\prec$.

% \begin{mydef}
% For two computations $k_i(R_i,w_i,\text{exp}_i)$ and $k_j(R_j,w_j,\text{exp}_j)$, a time dependency is denoted $k_i \blacktriangleleft k_j$ and means that $k_i$ has to be computed before $k_j$.
% \end{mydef}

% As a result, the relation $\blacktriangleleft$ is more general than $\prec$.

% \begin{myprop}
% For two computations $k_i(R_i,w_i,\text{exp}_i)$ and $k_j(R_j,w_j,\text{exp}_j)$ such that $k_i \prec k_j$, $k_i \blacktriangleleft k_j$ is verified.
% \end{myprop}

% \begin{proof}
% By definition $k_i \prec k_j$ means that $\{w_i\}\cap R_j \neq \emptyset$ and that $k_i$ has to computed before $k_j$. %Thus, the relation $k_i \prec k_j$ is stronger than $k_i \blacktriangleleft k_j$.
% \end{proof}

% \begin{myprop}
% The binary relation $\blacktriangleleft$ is transitive. 
% \end{myprop}

% \begin{proof}
% Considering three computations $c_0(R_0,w_0,\text{exp}_0)$, $c_1(R_1,w_1,\text{exp}_1)$ and $c_2(R_2,w_2,\text{exp}_2)$, where $c_0 \blacktriangleleft c_1$ and $c_1 \blacktriangleleft c_2$. $c_0$ is computed before $c_1$ and $c_1$ is computed before $c_2$, as a result $c_0$ is computed before $c_2$ and the relation $c_0 \blacktriangleleft c_2$ is verified. 
% \end{proof}

\begin{mydef}
A directed acyclic graph (DAG) $G(V,A)$ is a graph where the edges are directed from a source to a destination vertex and where, following the direction of edges, no cycle can be found from a vertex $u$ to itself. A directed edge is called an arc, and for two vertices $v,u \in V$ an arc from $u$ to $v$ is denoted $(\overset{\frown}{u,v}) \in A$.
\end{mydef}

From an ordered list of computations $\Gamma_{sync}$, a directed dependency graph $\Gamma_{dep}(V,A)$ can be built finding all pairs of computations $k_i(R_i,w_i,\text{exp}_i,D_i)$ and $k_j(R_j,w_j,\text{exp}_j,D_j)$, with $i<j$, such that $k_i \prec k_j$. %Those time dependencies can be found from pairs of data dependencies $k_i \prec k_j$.

\begin{mydef}
For two directed graphs $G(V,A)$ and $G'(V',A')$, the union $(V,A)\cup (V',A')$ is defined as the union of each set $(V\cup V', A \cup A')$.
\end{mydef}

\begin{mydef}
From the ordered list $\Gamma_{sync}$ of computations $c(R,w,\text{exp},D)$, a directed dependency graph $\Gamma_{dep}(V,A)$ is obtained from the call $T_{dep}(\Gamma_{sync},0)$, where $F_{dep}$ is the recursive function
\begin{equation*}
F_{dep}(\Gamma_{sync},j) = 
\begin{cases} 	(\{\},\{\}) & \mbox{if }j=|\Gamma_{sync}|\\
				(k_j, \{(\overset{\frown}{k_i,k_j})\mbox{, }\forall i < j \mbox{, } k_i\prec k_j \})\cup F_{dep}(\Gamma_{sync},j+1) & \mbox{if }j<|\Gamma_{sync}|
\end{cases}
\end{equation*}
\end{mydef}

This constructive function is possible because the input is an ordered list. Actually, if $k_i\prec k_j$ then $i<j$. As a result, $k_i$ is already in $V$ when the arc $(\overset{\frown}{k_i,k_j})$ is built. 

\begin{myprop}
The directed graph $\Gamma_{dep}$ is an acyclic graph.
\end{myprop}

\begin{proof}
$\Gamma_{dep}$ is built from $\Gamma_{sync}$ which is an ordered and sequential list of computations. Moreover, each computation of the list $\Gamma_{sync}$ is associated to a vertex of $V$, even if the same computation is represented more than once in $\Gamma_{sync}$. As a result it is not possible to go back to a previous computation and to create a cycle.
\end{proof}

As a result, the hybrid parallelization of a multi-stencil program $\mathcal{MSP}$, produces $k$ multi-stencil programs
\begin{equation*}
\mathcal{MSP}_k(T,\mathcal{M}_k,\mathcal{E},\mathcal{D},\Delta_k,\Gamma_{dep}).
\end{equation*}
The set of computations $\Gamma_{dep}$ is a dependency graph between computations $k_i$ of $\Gamma$ and the synchronization computations $synk_i$ added into $\Gamma_{sync}$. $\Gamma_{dep}$ can be built from the call to 
\begin{equation*}
F_{dep}(F_{sync}(\Gamma,0),0).
\end{equation*}

% Using the function $T_{task}$ to build $\Gamma_{task}$, however, duplication of dependencies may occur because of the transitivity of the relation $\blacktriangleleft$. Actually, as the relation $\prec$ verifies the relation $\blacktriangleleft$, and as $\blacktriangleleft$ is transitive, if for three computations $c_k(R_k,w_k,\text{exp}_k)$, $k_i(R_i,w_i,\text{exp}_i)$ and $k_j(R_j,w_j,\text{exp}_j)$, with $k<i<j$ and where $c_k \prec k_i$, $k_i \prec k_j$ and $c_k \prec k_j$, then the transitivity $c_k \blacktriangleleft k_j$ is verified because of the relations $c_k \blacktriangleleft k_i$ and $k_i \blacktriangleleft k_j$. However, $c_k \blacktriangleleft k_j$ is also directly represented by the binary relation $c_k \prec k_j$. As a result, a duplication of the dependency is created in $\Gamma_{task}$. In Figure~\ref{fig:duplication} an example of duplication is given for the relation $c_1 \blacktriangleleft c_4$.

% \begin{figure}[h!]
% \begin{center}
% \begin{tikzpicture}[shorten >=1pt, node distance=2cm, on grid, auto]
%    \node[] (c0) at (0,0) {$c_0$};
%    \node[] (c1) at (1,0) {$c_1$};
%    \node[] (c2) at (2,0) {$c_2$};
%    \node[] (c3) at (3,0) {$c_3$};
%    \node[] (c4) at (4,0) {$c_4$};
 
%   \path[->]
%     (c0) edge node {} (c1)
%     (c1.east) edge node {} (c2)
%     	 edge [bend right=50] node [swap] {} (c4)
%     (c2) edge node {} (c3)
%     (c3) edge node {} (c4);
%   \end{tikzpicture}
%   \caption{Useless duplication of the dependency $c_1 \blacktriangleleft c_4$}
%   \label{fig:duplication}
% \end{center}
% \end{figure}

% Another view of the relations $\prec$ and $\blacktriangleleft$ is that $k_i\blacktriangleleft k_j$ in $\Gamma_{task}$ is a path from $k_i$ to $k_j$ of any size, while $k_i \prec k_j$ is a path of size $1$ from $k_i$ to $k_j$. And in any case a path in the graph represents a time dependency between computations. Scheduling a graph dependency which do not contains duplication of information is easier. 
% %For this reason, we define a reduction to apply to $\Gamma_{task}$, and which is performed as a post-transformation. In the example of Figure~\ref{fig:duplication} the dependency represented by the path $c_1 \blacktriangleleft c_2 \blacktriangleleft c_3 \blacktriangleleft c_4$ gives more information than the one directly represented by $c_1 \prec c_4$. The proposed reduction is based on this property.

% % \begin{mydef}
% % The dependency graph $\Gamma_{task}(V,A)$ is reduced to the dependency graph $\Gamma_{task}(V,A')$, where $A' \subseteq A$. A direct arc $(\overset{\frown}{k_i,k_j})$, $i<j$, of $A$, which means that $k_i \prec k_j$, is included in $A'$ if no longer path $k_i \blacktriangleleft k_j$ exists in $A$ because of transitivity.
% % \end{mydef}
% \begin{mydef}
% A DAG is transitive if it contains an arc $(\overset{\frown}{u,v})$ between any two vertices such that there is a path from $u$ to $v$. The transitive closure of a DAG $G=(V,E)$, is the DAG $G_T=(V,E_T)$ for which $E_T$ is the minimal subset of $V \times V$ that includes $E$ and makes $G_T$ transitive.
% \end{mydef}

% \begin{mydef}
% An arc $(\overset{\frown}{u,v})$ of a DAG is redundant if there is a path from $u$ to $v$ in the DAG that does not include the edge. A DAG that does not contain any redundant arc is called minimal. The transitive reduction of a DAG $G$ is its unique minimal sub-graph having the same transitive closure.
% \end{mydef}

% Thus, the removal of the redundant dependencies of $\Gamma_{task}$ consists in applying a transitive reduction.


%------------------------------
% \subsection{Hybrid parallelism}
% It is also possible to combine data and task parallelization techniques to get hybrid parallelism, sometimes more efficient on hybrid architectures. A coarse-grain data parallelism creates for $k$ resources $k$ multi-stencil computations $\mathcal{MSP}_k(T,\mathcal{M}_k,\Delta_k,\Gamma_{data})$, where $\Gamma_{data}$ is built from an ordered list of computations and is itself an ordered list of computations $k_i$ and updated-computations $*_i$. On the other hand, the task parallelization technique builds, from an ordered list of computation, a graph dependency $\Gamma_{task}$. As a result $T_{data}$ and $T_{task}$ can be composed to build $\Gamma_{hybrid}$. 

% However, we have to clarify the dependency operator $\prec$ for the specific case of updated-computations. As explained in Section~\ref{sect:dataparal}, if $k_j$ is an updated-computations, which means that at least one $k_i$ exists such that $i<j$ and $k_i \pprec k_j$, $k_j$ is transformed to the ordered list of two computations

% \begin{equation*}
% [*_j(R^*_j,w^*_j),c^*_j(R_j \cup \{w^*_j\},w_j,\text{exp}_j)].
% \end{equation*}

% As a result, and because $*_j$ is itself a computation, it appears dependencies relations. First, by definition, the dependency $c^*_j \prec *_j$ is created because $\{w^*_j\} \subset R_j \cup \{w^*_j\}$. Second, as $R^*_j = \{\bigcup_{i} \{w_i\} \text{, }\forall i<j\text{, and }k_i \pprec k_j\}$, for each $i<j$ the dependency $k_i \prec *_j$ is also created.

% The choice of separating $*_j$ from $k_j$ has been done to entirely expose the eventual task parallelism in the hybrid parallelization. For example, Figure~\ref{fig:more} give an exemple where initially $c_0 \pprec c_2$ and $c_0 \prec c_1$, $c_1 \prec c_2$. Thus, $c_2$ is replaced first in $\Gamma_{data}$ by $[*_2(\{w_0\},w^*_2),c^*_2(R_2 \cup \{w^*_2\},\text{exp}_2)]$. As a result, when applying $T_{task}$ on $\Gamma_{data}$, it appears that $*_2$ can be performed in parallel with $c_1$. This is due to the fact that $*_2$ is splitted from from $c_2$ and that $R^*_2=\{w_0\}$ is a subset of $R_2=\{w_0,w_1\}$ and not equal to $R_2$.

% \begin{figure}[h!]
% \begin{center}
% \begin{tikzpicture}[shorten >=1pt, node distance=2cm, on grid, auto]
%    \node[] (c0) at (0,0) {$c_0$};
%    \node[] (c1) at (2,0) {$c_1$};
%    \node[] (star2) at (2,1) {$*_2$};
%    \node[] (c2) at (4,0) {$c^*_2$};
 
%   \path[->]
%     (c0) edge node {} (c1)
%          edge node {} (star2)
%     (c1) edge node {} (c2)
%     (star2) edge node {} (c2);
%   \end{tikzpicture}
%   \caption{Example of hybrid parallelization.}
%   \label{fig:more}
% \end{center}
% \end{figure}

% As a result, the hybrid parallelization of a multi-stencil program $\mathcal{MSP}$, produces $k$ multi-stencil programs
% \begin{equation*}
% \mathcal{MSP}_k(T,\mathcal{M}_k,\Delta_k,\Gamma_{hybrid}).
% \end{equation*}
% The set of computations $\Gamma_{hybrid}$ is a dependency graph between computations $k_i$ and update computations $*_i$, and can be built from the call to 
% \begin{equation*}
% T_{task}(T_{data}(\Gamma,0),0).
% \end{equation*}

% The rest of this paper deals with the hybrid parallelization of multi-stencil programs described above. The reason of this choice is the fact that by adressing the hybrid parallelism case, we also are able to adress data parallelism and task parallelism, from which hybrid parallelism is built.

