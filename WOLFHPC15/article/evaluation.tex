Navier-Stokes equations is a well known set of PDEs in fluid dynamics to simulate a flow evolution in time. At the University of Orl\'eans, France, the MAPMO laboratory works on a software, called FullSWOF~\footnote{\url{http://www.univ-orleans.fr/mapmo/soft/FullSWOF/}}, which solves the Shallow water equations obtained from the three dimensional Navier-Stokes equations, by averaging on the vertical direction (see e.g.~\cite{Ferrari2004}). Those equations are solved using a two-dimensional Cartesian discretization of the space domain, and a finite volume numerical methods more described in~\cite{HeleneLS13}.

\subsubsection*{Compiler Evaluation}

The series-parallel tree decomposition extracted by the MSC transformation is composed of seventeen sequences and eighteen parallel sections. Figure~\ref{fig:freq} represents for a given level of parallelism, \ie the number of tasks which can be executed concurrently, the number of time this level is observed in the final component assembly. One can notive that the level of task parallelism extracted from the Shallow water equations is limited by at the two sequential parts of the application (level 1). However, as a level of sixteen parallel tasks is reach too times, but also five times for the level six, sequential restrictions could be amortize. Moreover, as the level of parallelism in the application is heterogenous, the choice of the number of threads to launch for task parallelism is difficult.

\begin{figure}[!h]
 \begin{center}
 \begin{tabular}{c|c|c|c|c|c|c|c|c|}
   level & 1 & 2 & 3 & 4 & 6 & 10 & 12 & 16\\
   \hline
   frequence & 2 & 1 & 3 & 5 & 3 & 1 & 1 & 2\\
 \end{tabular}
\caption{Parallelism level (number of parallel tasks) and the number of times this level appears.}
\label{fig:freq}
 \end{center}
\end{figure}

Figure~\ref{fig:exectime} illustrates the execution time for each step of the MSC transformation for an overall execution time of ten seconds. Execution times have been computed on a laptop with a bi-core Intel Core i5 1,4 GHz, and 8Gb LPDDR3. 
\begin{figure}[!h]
 \begin{center}
 \begin{tabular}{c|c|c|c|c|}
   step & $\Gamma_{sync}$ & $\Gamma_{dep}$ & $\Gamma_{msp}$ & $\Gamma_{tsp}$\\
   \hline
   time (ms) & 2 & 530 & 8297 & 1133\\
   \hline
   \% & 0.02 & 5.3 & 83.3 & 11.37\\
 \end{tabular}
\caption{Execution times of the MSC transformation steps}
\label{fig:exectime}
 \end{center}
\end{figure}
One can notice that the transformation of $\Gamma_{dep}$ to a minimal series-parallel graph is the longest step of MSC, because of the removal of the forbidden shapes in the graph. Actually, the number of forbidden shapes removed in $\Gamma_{dep}$ is not counted, because the algorithm uses a general solution instead of finding each forbidden shape, but it seems that many of them appeared. The \emph{N-shape}, represented in Figure~\ref{fig:n} is forbidden in a minimal series-parallel graph as it is not possible to exactly express it using sequences and parallel sections.
The fact that many \emph{N-shape} are removed in $\Gamma_{dep}$ shows that the creation of a static shedule of tasks may not be the best solution for complex simulations. Actually, if a \emph{N-shape} cannot be represented by sequences and parallel sections, this shape can perfectly be handled by a dynamic scheduler or by the direct static representation of $\Gamma_{dep}$ where tasks wait for their input before starting.

\subsubsection*{Preliminary Performances}
To evaluate if performances of the overall automatic parallelization are promising we have proceeded as follows. Our current implementation of the MSCAC compiler generates a back-end code using the SkelGIS library. For this reason, our evaluation compare the shallow water equations first parallelized with a pure SkelGIS code (data structures, applicators and interfaces of SkelGIS~\cite{CPE:CPE3494}), and second parallelized with MSL (which uses the SkelGIS data structure). As the SkelGIS library has proved its scalability on the Shallow water equations compared to an MPI parallelization, the evaluation is relevant to evaluate scalability of MSL. 
Moreover, as SkelGIS library handles data parallelization for distributed memory architectures, we have limited for now our evaluations to the fusionned data parallelization of MSCAC (dumped from $\Gamma_{data}$). 

\fix{HC : preciser la machine}

Evaluations have been performed on ... . Figure~\ref{fig:times} shows the execution times in seconds as a function of the number of cores. Figure~\ref{fig:speedup} illustrates a speedup comparison, using the minimum sequential reference time (which is the MSL sequential time). Finally, Figure~\ref{fig:log2} illustrates the logarithmic scale of execution times as a function of the logarithmic scale of the number of cores.
\begin{figure}[!h]
 \begin{center}
 \begin{tabular}{c|c|c|c|c|c|c}
   cores & 8 & 16 & 32 & 64 & 128 & 256\\
   \hline
   MSL & 998.10 & 544.86 & 285.73 & 139.8 & 76.45 & 48.05\\
   \hline
   SkelGIS & 1324.9 & 638.5 & 371.62 & 197.32 & 117.05 & 64.96\\
 \end{tabular}
\caption{Execution times for the shallow water equations using MSL and SkelGIS (in seconds).}
\label{fig:times}
 \end{center}
\end{figure}
\begin{figure*}
\begin{center}
\subfloat[\label{fig:speedup}]{
\resizebox{8cm}{!}{\includegraphics{./images/speedup.pdf}}
}
\hspace{10pt}
\subfloat[\label{fig:log2}]{
\resizebox{8cm}{!}{\includegraphics{./images/logtime.pdf}}
}
\end{center}
\caption{(a) Speedup comparison, and (b) logarithmic execution times, both for the Shallow water equations, using pure SkelGIS and MSL with the SkelGIS data structure.}
\label{fig:perfs}
\end{figure*}

One can notive that execution times using MSL, which itself uses the SkelGIS distributed data structures, is improved compared to a pure SkelGIS parallelization. Moreover, the scalability stays close to the scalability of SkelGIS even if the makespan is improved.
