%----------------------------------------
\subsection{MS language}
%----------------------------------------
The MS language (MSL) is an agnostic descriptive language for multi-stencil simulations. MSL follows the definition of a multi-stencil program~(\ref{eq:msp}), and of stencil and local computations~(\ref{eq:st}) and~(\ref{eq:loc}). Thus, it is composed of six sections: the mesh description; the mesh domains description; the computation domains description; the data description; the time loop description; and finally, the computations description.

The overall grammar of a MSL program is given in Figure~\ref{fig:grammar}, where the terminals $meshid$, $meshdom$, $compdomid$, $dataid$, $compid$ are string identifiers, and $num$ is an integer value. An example is then given to explain each section.

\begin{figure}[h!]
\begin{lstlisting}[basicstyle=\small,mathescape,frame=single,language=C++]
program ::= "mesh:" meshid 
            "mesh domains:" listmeshdom
            "computation domains:" 
                       listcompdom
            "independent:"
                       listinde
            "data:" listdata
            "time:" iteration
            "computations:" listcomp
listmeshdom ::= meshdom listmeshdom
             |  meshdom
listcompdom ::= compdom listcompdom
             |  compdom
compdom ::= compdomid "in" listmeshdom
listinde ::= inde listinde
          |  inde
inde ::= compdomid and compdomid
listdata ::= data listdata
          |  data
data ::= dataid "," meshdom
iteration ::= num
listcomp ::= comp listcomp
          |  comp
comp ::= dataid "[" compdomid "]=" compid "(" 
            listdataread ")"
listdataread ::= dataread listdataread
              |  dataread
dataread ::= dataid "[" neighborid "]"
\end{lstlisting}
\caption{Grammar of the MS language}
\label{fig:grammar}
\end{figure}

\paragraph{Mesh and mesh domains} A mesh is defined by a string identifier. As already explain, this work is for now limited to a single mesh. Each mesh domain is also represented by a string identifier. For example
\begin{lstlisting}[basicstyle=\small,mathescape,frame=single,language=C++]
mesh: cart
mesh domains: cell,edgex,edgey
\end{lstlisting}

\paragraph{Computation domains} A computation domain can be seen as a subpart of a meh domain which will be used during computation phase. For each computation domain is indicated the mesh domain identifier from which it is built. By default two computation domains always intersect except when precise in the section \emph{no intersections}. For example
\begin{lstlisting}[basicstyle=\small,mathescape,frame=single,language=C++]
computation domains:
  allcell in cell
  alledgex in edgex
  alledgey in edgey
  part1edgex in edgex
  part2edgex in edgex
independent:
  part1edgex and part2edgex
\end{lstlisting}
In this example, an entire computation domain is defined for each mesh domain, and additionnally two subpart of the mesh domain edgex are defined. It is then precised that part1edgex and part2edgex do not intersect.

\paragraph{Data and time} A data is a quantity to simulate and is mapped onto a mesh domain. The time section simply indicates a number of iterations to perform in the simulation. For example:
\begin{lstlisting}[basicstyle=\small,mathescape,frame=single,language=C++]
data:
  a,cell
  b,cell
  c,edgex
  d,edgex
  e,edgey
  f,cell
  g,edgey
  h,edgex
  i,cell
  j,edgex
time:500
\end{lstlisting}

\paragraph{Computations description} The most important part of MSL is the description of the computations of the simulation. The language follows the definitions given in Section~\ref{sect:multistencil}, however as MSL is not made to express numerical computations, the element $exp$ of the definition is not given in the language. Moreover, to propose a syntax close to an imperative code, information are given in a different order.
Thus, the description of a computation consists of the identifier of the data to compute, the computation domain (which is a subpart of the mesh domain of the data) on which it is computed into the brackets, an identification name of the computation, and a set of identifiers for the data read by the computation. For each data read by the computation brackets indicate the stencil shape identifier used on the data. If the computation is local brackets stay empty. In the example below, the data $b$ is computed on the computation domain $allcell$ by the computation $c_0$ which read data $a$ without neighborhood shape.
\begin{lstlisting}[basicstyle=\small,mathescape,frame=single,language=C++]
computations:
  b[allcell]=c0(a[])
  c[alledgex]=c1(b[n1])
  d[alledgex]=c2(c[])
  e[alledgey]=c3(c[])
  f[allcell]=c4(d[n1])
  g[alledgey]=c5(e)
  h[alledgex]=c6(f)
  i[allcell]=c7(g[],h[])
  j[partedgex]=c8(i[n1])
\end{lstlisting}

%----------------------------------------
\subsection{MSC compiler}
%----------------------------------------
The MSC compiler, which is a subpart of the overall compiler MSCAC, performs an algorithm composed of six main steps described bellow:

\begin{enumerate}
\item creation of $\Gamma$, the ordered list of computations, from the MSL input file;
\item creation of $\Gamma_{data}$ the ordered list of computations including synchronizations;
\item creation of the dependency graph $\Gamma_{hybrid}$;
\item transformation of $\Gamma_{hybrid}$ to a minimal series-parallel graph $\Gamma_{msp}$;
\item creation of the series-parallel tree decomposition $\Gamma_{tsp}$;
\item dump $\Gamma_{tsp}$ to a component assembly.
\end{enumerate}

\paragraph{Creation of the ordered list of computations} This step of the MSC compiler parse the MSL input file which describes the simulation. From the ordered lines of computations, it builds the ordered list of computations $\Gamma$ to perform in the simulation. For example the ordered list of computation of the example above is $[c_0,c_1,c_2,c_3,c_4,c_5,c_6,c_7,c_8]$.

\paragraph{Creation of the synchronized ordered list of computations} From the ordered list of computations $\Gamma$ it is possible to detect needed synchronizations if a \emph{data parallelization} is performed on the simulation. A synchronization is needed each time a data read by a stencil computation has been written by a previous computation and if the computation domains intersect. Actually, as a stencil computation needs neighborhood values, in a domain decomposition values computed by different processors or cores are needed.

For example, the stencil computation $c_1$ read the data $b$ which has been written by the computation $c_0$. Moreover the mesh domains are different which means that the computation domains intersect. For this reason the sublist $[c_0,c_1]$ of $\Gamma$ is transformed to the sublist $[c_0,sync_1,c_1]$ in $\Gamma_{data}$. The new computation $sync_1$ read and write $b$. As a result a dependency is kept between $sync_1$, and $c_1$. The same is performed for the stencils $c_4$ and $c_8$.

\paragraph{Creation of the dependency graph} From the synchronized ordered list of computations $\Gamma_{data}$, a dependency graph can be build. A dependency exists between two computations (including synchronizations) if and only if a data read has been written by a previous computation in $\Gamma_{data}$, and if the computation domains intersect. In other words, the only case where a data dependency exists but is not taking into account is when the computation domains do not intersect. Nodes of the dependency graph represent computations and synchronizations, while edges are dependencies between them. $\Gamma_{hybrid}$ is a directed acyclic graph (\emph{dag}) as it is build from an ordered list. For example, the dependency dag $\Gamma_{hybrid}$ of the example is illustrated in Figure~\ref{fig:hyb}.

\begin{figure}[h!]
\begin{center}
\begin{tikzpicture}[shorten >=1pt, node distance=2cm, on grid, auto]
   \node (c0) at (0,0) {$c_0$};
   \node[right=1 of c0] (sy1) {$sync_1$};
   \node[right=1 of sy1] (c1) {$c_1$};
   \node[above right=1 of c1] (c2) {$c_2$};
   \node[below right=1 of c1] (c3) {$c_3$};
   \node[right=1 of c2] (sy4) {$sync_4$};
   \node[right=1 of c3] (c5) {$c_5$};
   \node[right=1 of sy4] (c4) {$c_4$};
   \node[right=1 of c4] (c6) {$c_6$};
   \node[below right=1 of c6] (c7) {$c_7$};
   \node[right=1 of c7] (sy8) {$sync_8$};
   \node[right=1 of sy8] (c8) {$c_8$};
 
  \path[->]
    (c0) edge node {} (sy1)
    (sy1) edge node {} (c1)
    (c1)  edge node {} (c2)
          edge node {} (c3)
    (c2) edge node {} (sy4)
    (sy4) edge node {} (c4)
    (c4) edge node {} (c6)
    (c3) edge node {} (c5)
    (c5) edge node {} (c7)
    (c6) edge node {} (c7)
    (c7) edge node {} (sy8)
    (sy8) edge node {} (c8);
\end{tikzpicture}
\caption{$\Gamma_{hybrid}$ of Figure~\ref{fig:msinput}}
\label{fig:hyb}
\end{center}
\end{figure}


\paragraph{Transformation to a minimal series-parallel graph} As it has been shown in~\cite{Valdes:1979:RSP:800135.804393}, the transitive reduction of a dag is a minimal series-parallel graph if and only if the forbidden \emph{N-shape} is not found in the graph. To transform $\Gamma_{hybrid}$ to the minimal series-parallel graph $\Gamma_{msp}$, a breadth first search~\cite{} traversing algorithm is applied to build a complete bipartite graph between two levels of $\Gamma_{hybrid}$~\cite{Mitchell:2004:CMV:1082101.1082117}.

\paragraph{Creation of a tree decomposition} As shown in different works~\cite{Valdes:1979:RSP:800135.804393,Schoenmakers95anew}, from a minimal series-parallel graph a tree decomposition can be built. A series-parallel tree decomposition consists in the decomposition of the graph as a set of \emph{sequences} and \emph{parallel} sections in a tree. For example, the series-parallel tree decomposition $\Gamma_{tsp}$ of the example is illustrated in Figure~\ref{fig:canon}.

\begin{figure}[h!]
\begin{center}
\begin{tikzpicture}[shorten >=1pt, node distance=2cm, on grid, auto]
   \node[] (s0) at (0,0) {$\mathcal{S}$};
   \node[] (c0) at (-3,1) {$c_0$};
   \node[] (star1) at (-2,1) {$sync_1$};
   \node[] (c1) at (-1,1) {$c_1$};

   \node[] (p0) at (0,1) {$\mathcal{P}$};
   \node[] (s1) at (-1,2) {$\mathcal{S}$};
   \node[] (p1) at (-2,3) {$\mathcal{P}$};
   \node[] (c4) at (-1,3) {$c_4$};
   \node[] (c6) at (-0,3) {$c_6$};
   \node[] (c2) at (-2.5,4) {$c_2$};
   \node[] (star4) at (-1.5,4) {$sync_4$};
   \node[] (s2) at (1,2) {$\mathcal{S}$};
   \node[] (c3) at (0.5,3) {$c_3$};
   \node[] (c5) at (1.5,3) {$c_5$};

   \node[] (c7) at (1,1) {$c_7$};
   \node[] (star8) at (2,1) {$sync_8$};
   \node[] (c8) at (3,1) {$c_8$};
 
  \path[->]
    (s0) edge node {} (c0)
         edge node {} (star1)
         edge node {} (c1)
         edge node {} (p0)
         edge node {} (c7)
         edge node {} (star8)
         edge node {} (c8)
    (p0) edge node {} (s1)
         edge node {} (s2)
    (s1) edge node {} (p1)
         edge node {} (c4)
         edge node {} (c6)
    (p1) edge node {} (c2)
         edge node {} (star4)
    (s2) edge node {} (c3)
         edge node {} (c5);
  \end{tikzpicture}
\caption{$\Gamma_{tsp}$ of Figure~\ref{fig:hyb}.}
\label{fig:canon}
\end{center}
\end{figure}

\paragraph{Dump to a component assembly} From the series-parallel tree decomposition $\Gamma_{tsp}$ can be built a program using any parallel language containing \emph{parallel sections} and \emph{sequences of instructions} such as OpenMP~\cite{660313}, HPF~\cite{219857}, UPC~\cite{El-Ghazawi:2006:UUP:1188455.1188483} etc. In this paper we study the dump of $\Gamma_{tsp}$ to a component assembly which needs the introduction of \emph{control components} described in the next section.

For more details on MSC, a full description of the compilation is described in the research report~\cite{}.


