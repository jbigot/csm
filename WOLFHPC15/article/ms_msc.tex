%----------------------------------------
\subsection{Multi Stencil Language}
%----------------------------------------
As already mentionned, the Multi Stencil Language (MSL) is an agnostic descriptive language for multi-stencil simulations. Six main sections are required in a MSL description, as the six tuples of the formal definition of a multi-stencil program: the mesh description; the mesh entities description; the computation domains description and their dependencies; the data description; the time loop description; and finally, the computations description. Figure~\ref{fig:grammar} shows the grammar of MSL. Lines 1 to 9 of this figure define what is a MSL program with the different sections described above. In this section are described the different sections of a MSL program and an example.
As MSL is a descriptive language, almost all terminals $meshid$, $meshdom$, $compdomid$, $dataid$, $compid$ ans $neighborid$ are string identifiers. Only $num$ is an integer terminal.

\begin{figure}[h!]
\begin{lstlisting}[basicstyle=\small,mathescape,frame=single,language=C++,numbers=left]
program ::= "mesh:" meshid 
            "mesh entities:" listmeshent
            "computation domains:" 
                       listcompdom
            "independent:"
                       listinde
            "data:" listdata
            "time:" iteration
            "computations:" listcomp
listmeshent ::= meshent listmeshent
             |  meshent
listcompdom ::= compdom listcompdom
             |  compdom
compdom ::= compdomid "in" listmeshent
listinde ::= inde listinde
          |  inde
inde ::= compdomid "and" compdomid
listdata ::= data listdata
          |  data
data ::= dataid "," meshent
iteration ::= num
listcomp ::= comp listcomp
          |  comp
comp ::= dataid "[" compdomid "]=" compid "(" 
            listdataread ")"
listdataread ::= dataread listdataread
              |  dataread
dataread ::= dataid "[" neighborid "]"
          |  dataid
\end{lstlisting}
\caption{Grammar of the MS language}
\label{fig:grammar}
\end{figure}

\paragraph{Mesh and mesh entities} As illustrated in the first line of the grammar in Figure~\ref{fig:grammar}, a mesh is directly defined by a string identifier. Mesh entities are described as a list of identifiers (lines 2, 10 and 11 in Figure~\ref{fig:grammar}). In the example given in Figure~\ref{fig:mslex} a Cartesian mesh, called $cart$, and three mesh entities, called $cell$, $edgex$ and $edgey$, are defined.

\paragraph{Computation domains and their dependencies} A computation domain can be seen as a subpart of a mesh entity which will be used during one or more computations. For each computation domain is indicated the mesh entity from which it is built (lines 3-4 and 12-14 in Figure~\ref{fig:grammar}). By default two computation domains always intersect except when an independency relation is precised in the section \emph{independent} of the language (lines 5-6 and 15-17 in Figure~\ref{fig:grammar}). In the example of Figure~\ref{fig:mslex}, on lines 4 to 6 an entire computation domain is defined for each mesh entity, called $allcell$, $alledgex$ and $alledgey$, and on lines 7 and 8 two subparts of the mesh entity edgex are also defined, called $part1edgex$ and $part2edgex$. It is then precised on line 10 that $part1edgex$ and $part2edgex$ do not intersect.

\paragraph{Data and time} A data is a quantity to simulate and is mapped onto a mesh entity, as illustrated in lines 7 and 18-20 f Figure~\ref{fig:grammar}. The time section simply indicates a number of iterations to perform in the simulation. In the example of Figure~\ref{fig:mslex} are defined ten data and 500 iterations (lines 11-22).

\paragraph{Computations description} Finally the language follows the two definitions of a stencil computation and a local computation given in Section~\ref{sect:multistencil}. However as MSL does not handle numerical expressions, the term $exp$ of Definition~\ref{eq:st} and Definition~\ref{eq:loc} is not used in the language. The exact code of the computation as to be writtenin the final ready-to-fill parallel pattern of the simulation, using external languages or interfaces. Moreover, to propose an intuitive syntax, information are given in a different order than in formal definitions.
Thus, the description of a computation, as indicated in lines 24 and 25 of Figure~\ref{fig:grammar}), consists in first the identifier of the data to compute ($w$ in the formal description), brackets indicated the computation domain on which the computation is applied ($d_c$ in the formal definition), an identifier for the computation, and the set of identifiers for the data read by the computation. For each data read by the computation brackets indicate the stencil shape identifier used on the data ($R$ in the formal definition of a stencil). If the computation is local no brackets appear ($R_l$ in the formal definition). In the example of Figure~\ref{fig:mslex}, nine computations are described. For example, on line 24, the data $b$ is computed on the computation domain $allcell$ by the computation $c_0$ which read data $a$ without neighborhood shape.
\begin{figure}
\begin{lstlisting}[basicstyle=\small,mathescape,frame=single,language=C++,numbers=left]
mesh: cart
mesh domains: cell,edgex,edgey
computation domains:
  allcell in cell
  alledgex in edgex
  alledgey in edgey
  part1edgex in edgex
  part2edgex in edgex
independent:
  part1edgex and part2edgex
data:
  a,cell
  b,cell
  c,edgex
  d,edgex
  e,edgey
  f,cell
  g,edgey
  h,edgex
  i,cell
  j,edgex
time:500
computations:
  b[allcell]=c0(a)
  c[alledgex]=c1(b[n1])
  d[alledgex]=c2(c)
  e[alledgey]=c3(c)
  f[allcell]=c4(d[n1])
  g[alledgey]=c5(e)
  h[alledgex]=c6(f)
  i[allcell]=c7(g,h)
  j[partedgex]=c8(i[n1])
\end{lstlisting}
\caption{Example of a MSL program}
\label{fig:mslex}
\end{figure}

%----------------------------------------
\subsection{MSC transformation}
%----------------------------------------
The MSC transformation, which is a subpart of the overall compiler MSCAC, use the ordered list of computations $\Gamma$, which can directly been extracted from the parser, to build a parallel representation of the computations of the overall multi-stencil program. This transformation phase of the compilation is divided in four different steps and transform $\Gamma$ to a series-parallel tree decomposition~\ref{}. This transformation phase handles data parallelism through the first step, and task parallelism through the three next steps. In this section are described those four steps of MSC. The detailed formalism and associated algorithms of those steps are described in the research report~\cite{}.

The creation of $\Gamma$ is directly given from the parser. Actually, the list of computations in the MSL program is already ordered, as a result $\Gamma$ is a direct map of this list. In the example of Figure~\ref{fig:mslex}, $\Gamma = [c_0,c_1,c_2,c_3,c_4,c_5,c_6,c_7,c_8]$.

\paragraph{Creation of the synchronized ordered list of computations} Considering a data parallelization of the simulation, the mesh and data of the simulation are splitted among available processors (or cores) and a single program is applied on each sub-part with additionnal synchronizations between processors or cores. For example, as a stencil code access neighborhood value, values computed by another processor are needed and synchronized. 
From the ordered list of computations $\Gamma$ can be automatically detected the needed synchronizations. A synchronization is needed each time a data read by a stencil computation has been written by a previous computation. In such a case, a computation is added before the stencil computation. This \emph{synchronization computation} read the data to synchronize, and write the same data. The computation domain of such a synchronization computation is the mesh entity on which the data is declared. As a result $\Gamma$ is transformed to a synchronized ordered list of computations $\Gamma_{data}$.
For example, in Figure~\ref{fig:mslex}, the stencil computation $c_1$ read the data $b$ which has been written by the computation $c_0$. For this reason the sublist $[c_0,c_1]$ of $\Gamma$ is transformed to the sublist $[c_0,sync_1,c_1]$ in $\Gamma_{data}$. The new computation $sync_1$ read and write $b$ and is applied on the computation domain of $c_1$. As a result, a dependency is kept between $c_0$ and $sync_1$ and between $sync_1$, and $c_1$. The same is performed for the stencils $c_4$ and $c_8$. Thus $\Gamma_{data} = [c_0,sync_1,c_1,c_2,c_3,sync_4,c_4,c_5,c_6,c_7,sync_8,c_8]$.

\paragraph{Creation of the dependency graph} From the synchronized ordered list of computations $\Gamma_{data}$, a dependency graph is built. A dependency exists between two computations (including synchronizations) if and only if a data read has been written by a previous computation in $\Gamma_{data}$, and if the computation domains intersect. In other words, the only case where a data dependency exists but is not taking into account is when the computation domains do not intersect. Nodes of the dependency graph represent computations of $\Gamma_{data}$, while edges are dependencies between them. The dependency graph $\Gamma_{hybrid}$ is a directed acyclic graph (\emph{dag}). For example, the dependency dag $\Gamma_{hybrid}$ of the example of Figure~\ref{fig:mslex} is illustrated in Figure~\ref{fig:hyb}.

\begin{figure}[h!]
\begin{center}
\begin{tikzpicture}[shorten >=1pt, node distance=2cm, on grid, auto]
   \node (c0) at (0,0) {$c_0$};
   \node[right=1 of c0] (sy1) {$sync_1$};
   \node[right=1 of sy1] (c1) {$c_1$};
   \node[above right=1 of c1] (c2) {$c_2$};
   \node[below right=1 of c1] (c3) {$c_3$};
   \node[right=1 of c2] (sy4) {$sync_4$};
   \node[right=1 of c3] (c5) {$c_5$};
   \node[right=1 of sy4] (c4) {$c_4$};
   \node[right=1 of c4] (c6) {$c_6$};
   \node[below right=1 of c6] (c7) {$c_7$};
   \node[right=1 of c7] (sy8) {$sync_8$};
   \node[right=1 of sy8] (c8) {$c_8$};
 
  \path[->]
    (c0) edge node {} (sy1)
    (sy1) edge node {} (c1)
    (c1)  edge node {} (c2)
          edge node {} (c3)
    (c2) edge node {} (sy4)
    (sy4) edge node {} (c4)
    (c4) edge node {} (c6)
    (c3) edge node {} (c5)
    (c5) edge node {} (c7)
    (c6) edge node {} (c7)
    (c7) edge node {} (sy8)
    (sy8) edge node {} (c8);
\end{tikzpicture}
\caption{$\Gamma_{hybrid}$ of Figure~\ref{fig:hyb}}
\label{fig:hyb}
\end{center}
\end{figure}

\paragraph{Transformation to a minimal series-parallel graph} Once a dependency graph is built many solutions can be used to build a parallel application, as for example dynamic schedulers~\cite{Augonnet2011,Gautier:2013:XRS:2510661.2511383}. In this work a static scheduling of the dependency graph is built. To do so the dependency graph is transformed to a minimal series-parallel graph~\cite{Valdes:1979:RSP:800135.804393}. As it has been shown in~\cite{Valdes:1979:RSP:800135.804393}, the transitive reduction of a dag is a minimal series-parallel graph if and only if a forbidden shape, called \emph{N-shape}, is not found in the graph. To transform $\Gamma_{hybrid}$ to the minimal series-parallel graph $\Gamma_{msp}$, a breadth first search algorithm is applied to build a complete bipartite graph between two levels of $\Gamma_{hybrid}$~\cite{Mitchell:2004:CMV:1082101.1082117}.

\paragraph{Creation of a tree decomposition} As shown in different works~\cite{Valdes:1979:RSP:800135.804393,Schoenmakers95anew}, from a minimal series-parallel graph a series-parallel tree decomposition can be built. A series-parallel tree decomposition consists in the decomposition of the minimal series-parallel graph as a tree representing a set of \emph{sequences}, indicated by a $S$ node, and \emph{parallel} sections, indicated as a $P$ node. For example, the series-parallel tree decomposition $\Gamma_{tsp}$ of Figure~\ref{fig:hyb} is illustrated in Figure~\ref{fig:tsp}.

\begin{figure}[h!]
\begin{center}
\begin{tikzpicture}[shorten >=1pt, node distance=2cm, on grid, auto]
   \node[] (s0) at (0,0) {$\mathcal{S}$};
   \node[] (c0) at (-3,1) {$c_0$};
   \node[] (star1) at (-2,1) {$sync_1$};
   \node[] (c1) at (-1,1) {$c_1$};

   \node[] (p0) at (0,1) {$\mathcal{P}$};
   \node[] (s1) at (-1,2) {$\mathcal{S}$};
   \node[] (p1) at (-2,3) {$\mathcal{P}$};
   \node[] (c4) at (-1,3) {$c_4$};
   \node[] (c6) at (-0,3) {$c_6$};
   \node[] (c2) at (-2.5,4) {$c_2$};
   \node[] (star4) at (-1.5,4) {$sync_4$};
   \node[] (s2) at (1,2) {$\mathcal{S}$};
   \node[] (c3) at (0.5,3) {$c_3$};
   \node[] (c5) at (1.5,3) {$c_5$};

   \node[] (c7) at (1,1) {$c_7$};
   \node[] (star8) at (2,1) {$sync_8$};
   \node[] (c8) at (3,1) {$c_8$};
 
  \path[->]
    (s0) edge node {} (c0)
         edge node {} (star1)
         edge node {} (c1)
         edge node {} (p0)
         edge node {} (c7)
         edge node {} (star8)
         edge node {} (c8)
    (p0) edge node {} (s1)
         edge node {} (s2)
    (s1) edge node {} (p1)
         edge node {} (c4)
         edge node {} (c6)
    (p1) edge node {} (c2)
         edge node {} (star4)
    (s2) edge node {} (c3)
         edge node {} (c5);
  \end{tikzpicture}
\caption{$\Gamma_{tsp}$ of Figure~\ref{fig:hyb}.}
\label{fig:tsp}
\end{center}
\end{figure}

% \paragraph{Dump to a component assembly} Finally, from the series-parallel tree decomposition $\Gamma_{tsp}$ we could build a program using any parallel language containing \emph{parallel sections} and \emph{sequences of instructions} such as OpenMP~\cite{660313}, HPF~\cite{219857}, UPC~\cite{El-Ghazawi:2006:UUP:1188455.1188483} etc. In this paper we study the dump of $\Gamma_{tsp}$ to a component assembly which needs the introduction of \emph{control components}, described in the next section.


