%----------------------------------------
\subsection{Stencil codes}
\label{sect:stencil}
%----------------------------------------
To numerically solve a set of PDEs, iterative methods (finite difference, finite volume, finite element methods etc.) are frequently used to approximate the solution through a discretized (step by step) phenomena. Thus, the continuous time and space domains are discretized so that a set of numerical computations are iteratively (time discretization) applied onto a mesh (space discretization). In other words, in a mesh-based numerical simulation, the PDEs are transformed to a set of numerical computations applied at each time step on elements of the discretized space domain (the mesh). Among those numerical computations is found a set of numerical schemes, also called \textit{stencil computations}~\cite{spaaTangCKLL11}. To ease programming of stencil computations, and because of the relative regularity of such a computation, many solutions (languages or libraries) propose an easy way to describe the stencil code, while producing transparently an optimized and parallelized stencil code. For example, Liszt~\cite{DeVito2011LDS} and OP2~\cite{Giles2011} are domain specific languages to define a stencil code on unstructured meshes, while Pochoir~\cite{spaaTangCKLL11} and PATUS~\cite{citeulike12258902} address structured meshes, respectively proposing an optimized cache tiling technique, and a separation of concerns by separating parallelization strategy from the computation description.

Let introduce some concepts used in this paper. First, a stencil code is based on a \emph{mesh} which is the discretization of the physical real domain. A mesh is a connected undirected graph without bridges (an edge is a bridge if its removal results in two disconnected graphs), where nodes and edges are linked to form cells (closure). For example, a structured mesh is illustrated in Figure~\ref{fig:ex}, each cell contains four nodes and four edges. Second, \emph{mesh domains} are subset elements of the mesh, such as the center of cells, edges or nodes, for example. In Figure~\ref{fig:ex} two mesh domains are used, the center of the cells (in red) and the edge on the horizontal axe (in blue on the left and right of each cell). A \emph{data} is a quantity to simulate or a temporary data to perform computations. A data is mapped onto a given mesh domain. For example, in Figure~\ref{fig:ex}, data $A$ and $B$ are mapped onto the center of cells, while $C$ is mapped onto the edges.

\begin{figure}
\begin{center}
\subfloat[Mesh and mesh domains\label{fig:mesh}]{
\resizebox{7cm}{!}{\includegraphics{./images/mesh.pdf}}
}
\hspace{10pt}
\subfloat[First stencil example\label{fig:ex1}]{
\resizebox{5cm}{!}{\includegraphics{./images/stencil1.pdf}}
}
\hspace{10pt}
\subfloat[Second stencil example\label{fig:ex2}]{
\resizebox{5cm}{!}{\includegraphics{./images/stencil2.pdf}}
}
\end{center}
\caption{Stencil examples}
\label{fig:gspmsp}
\end{figure}

% \begin{figure}[!h]\begin{center}
%   \resizebox{7cm}{!}{\includegraphics{./images/stencil.pdf}}
%   \caption{Examples of a stencil computations}
%   \label{fig:ex}
% \end{center}\end{figure}

The first stencil computation in Figure~\ref{fig:ex} computes $B$ using $A$, while the second one computes $B$ using $C$. Thus, a stencil computation is defined by a set of input data (in those examples only one input data), and a single output data, the result. The \emph{computation domain} is a subset of elements to compute on the output data. In other words a computation domain is a subset of a mesh domain. For example, in the first stencil, the computation of $B$ is performed on plain elements, while dotted elements are not computed. On the other hand, on the second computation, the computation domain of $B$ is exactly equal to the cell mesh domain. The computation domain represents the set of elements on which the computation is performed, in other words, the space loop.

Finally, a stencil computation is composed of a \emph{numerical expression} which indicates how to compute an element of the computation domain (on the output data), using elements of the set of input data. The numerical expression of a stencil computation has the particularity to use not only the element to compute but also a \emph{neighborhood} of this element, also called a \emph{stencil shape}. For example, the stencil shape of the first computation in Figure~\ref{fig:ex} contains direct neighbors on the right, left, top and bottom. Sometimes, the neighborhood shape can also access a different mesh domain, as for example in the second computation example. Actually, in this computation, the neighborhood contains edges on the left and on the right of the cell. As a result, we could imagine for example that the numerical expression of the first example is
\begin{equation*} 
B(x,y) = A(x+1,y)+A(x-1,y)+A(x,y+1)+A(x,y-1),
\end{equation*}
and that the numerical expression of the second example is
\begin{equation*} 
B(x,y) = B(x,y)+C(x1,y1)+C(x1+1,y1).
\end{equation*}

To conclude this section, we define a stencil computation $s$ as the quintuplet
\begin{equation} 
s(R,w,exp,\mathcal{N},d_c),
\label{eq:st}
\end{equation}
where $R$ is the set of input data, $w$ the output data, $exp$ the numerical expression of the stencil computation, which is applied on the computation domain $d_c$, using a stencil shape $\mathcal{N}$.

%----------------------------------------
\subsection{Multi-stencil programs}
\label{sect:multistencil}
%----------------------------------------
While stencil computations are well defined and a lot studied in the literrature, it is not the case for real case numerical simulations. In this paper, we define what we call a \emph{multi-stencil program}, which actually is a general numerical simulation. 

A real case numerical simulation is most of the time not composed of a single stencil computation, but of a set of stencil computations, with one or more stencil shapes (neighboorhood), and onto one or more data. Moreover, a numerical simulation also performs additionnal auxiliary computations which do not involve neighborhood, called local computations. This paper targets this general case of numerical simulations that we call \emph{multi-stencil programs}. The work presented produces a general parallelization structure of the overall simulation, while most stencil solutions produce optimized codes for a single stencil code. As it will be detailed in the related work, this work is complementary to the optimization and parallelization of a single stencil computation.

An auxiliary computation is almost the same than a stencil computation, however its numerical expression does not involve a neighborhood, which makes this kind of computation purely local. A local computation $l$ is defined as the quadruplet
\begin{equation} 
l(R,w,exp,d_c),
\label{eq:loc}
\end{equation}
where $R$ is the set of input data, $w$ the output data, $exp$ the numerical expression of the stencil computation, which is applied on the computation domain $d_c$.

A multi-stencil program in this work is defined as a sextuplet
\begin{equation} 
\mathcal{MSP}(T,\mathcal{M},\mathcal{D}_m,\mathcal{D}_c,\Delta,\Gamma),
\label{eq:msp}
\end{equation}
where $T$ is the set of time iteration to run the simulation, $\mathcal{M}$ is the mesh of the simulation, $\mathcal{D}_m$ is the set of mesh domains, $\mathcal{D}_c$ is the set of computation domains used into computations, $\Delta$ is the set of data, each one mapped onto a mesh domain, and finally $\Gamma$ is the set of computations. The set of computations $\Gamma$ is composed of an ordered list of stencil and local computations. One can notice that this work is limited to a single type of mesh in a given simulation.

% !!!!!!!!!!!! a mettre en plus court autre part !!!!!!!!!!!!!!!
%----------------------------------------
% \subsection{Parallelization techniques}
% \label{sect:parallel}
%----------------------------------------
% Three classical parallelization techniques are used in this paper and are described in this section, the data parallelism, the task parallelism, and the hybrid data and task parallelism. Those parallelization techniques are independent from the actual parallel hardware used.

% \paragraph{Data parallelism} The idea of this parallelization technique is to split, or partition, data on which computations are applied among available processors (or cores). Each processor then applies the same progam or instruction onto its subpart of data. Moreover, if a neighborhood information is needed from another processor communications or synchronizations are performed. 

% In the domain of numerical simulations, this technique is most of the time called a domain decomposition. This parallelization technique produce efficient programs up to thousands processors or cores, but on certain conditions. First, each subpart of data has to be big enough to overlap communication time. Second, the partitioning of data has to be balanced among processors. Thus, if this parallelization technique is clearly adequate to structured meshes, easy to balance, it is not for unstructured meshes or irregular structures where the amount of work is not heterogenous.

% \paragraph{Task parallelism} Another well known parallelization technique is to identify in a program the different tasks and which one are independant and can be launched concurrently. Most of the time, such a prallelization technique create a dependency directed acyclic graph (dependency dag) from a set of ordered tasks. Dependencies are found from read/write information for each task. Actually, if a task $i$ write a data $a$ and if a task $j$ read $a$, then $i$ has to be finished before $j$ is performed. From a dependency graph two different solutions are available. First, a static schedule of tasks is built, which could be a good solution if the tasks are regular, or use a dynamic scheduler to dynamically decide at runtime which task is executed on which processor.

% \paragraph{Hybrid parallelism} Finally, it is also possible to combine both those parallelization techniques to get what is called an hybrid parallelization. The interest of an hybrid parallelization is to bring another source of parallelism if limits of a given technique are reach.

