%----------------------------------------
\subsection{Stencil codes}
\label{sect:stencil}
%----------------------------------------
To numerically solve a set of PDEs, iterative methods (finite difference, finite volume, finite element methods etc.) are frequently used to approximate the solution through a discretized (step by step) phenomena. Thus, the continuous time and space domains are discretized so that a set of numerical computations are iteratively (time discretization) applied onto a mesh (space discretization). In other words, in a mesh-based numerical simulation, the PDEs are transformed to a set of numerical computations applied at each time step on elements of the discretized space domain (the mesh). Among those numerical computations is found a set of numerical schemes, also called \textit{stencil kernels}~\cite{spaaTangCKLL11}. %To ease programming of stencil kernels, and because of the relative regularity of such a computation, many solutions (languages or libraries) propose an easy way to describe the stencil code, while producing transparently an optimized and parallelized stencil kernel. For example, Liszt~\cite{DeVito2011LDS} and OP2~\cite{Giles2011} are domain specific languages to define a stencil kernel on unstructured meshes, while Pochoir~\cite{spaaTangCKLL11} and PATUS~\cite{citeulike12258902} address structured meshes, respectively proposing an optimized cache tiling technique, and a separation of concerns between parallelization strategies and computation descriptions.

%\fix{cp2hc: transition a revoir.}

In this paper are used rather unusual concepts to define a stencil, let introduce those concepts. First, a stencil kernel is based on a \emph{mesh} which is the discretization of the physical real domain. A mesh is a connected undirected graph without bridges (an edge is a bridge if its removal results in two disconnected graphs), where nodes and edges are linked to form cells (closure). For example, a structured mesh is illustrated in Figure~\ref{fig:mesh}. Each cell contains four nodes and four edges. Second, \emph{mesh entities} are subset elements of the mesh, such as the center of cells, edges or nodes. In Figure~\ref{fig:mesh}, two mesh entities are illustrated, the center of the cells (named \texttt{Cells}, in red) and edges on the horizontal axe (named \texttt{Edgex}, in blue on left and right of each cell). A \emph{data} is a quantity to simulate or a temporary data to perform computations. A data is mapped onto a given mesh entity. For example, in Figure~\ref{fig:ex1}, data $A$ and $B$ are mapped onto the center of cells, while, in Figure~\ref{fig:ex2}, $C$ is mapped onto the edges.

\begin{figure}
\begin{center}
\subfloat[Mesh and mesh domains\label{fig:mesh}]{
\resizebox{7cm}{!}{\includegraphics{./images/mesh.pdf}}
}
\hspace{10pt}
\subfloat[First stencil example\label{fig:ex1}]{
\resizebox{5cm}{!}{\includegraphics{./images/stencil1.pdf}}
}
\hspace{10pt}
\subfloat[Second stencil example\label{fig:ex2}]{
\resizebox{5cm}{!}{\includegraphics{./images/stencil2.pdf}}
}
\end{center}
\caption{Stencil examples}
\label{fig:gspmsp}
\end{figure}

% \begin{figure}[!h]\begin{center}
%   \resizebox{7cm}{!}{\includegraphics{./images/stencil.pdf}}
%   \caption{Examples of a stencil computations}
%   \label{fig:ex}
% \end{center}\end{figure}

The stencil kernel of Figure~\ref{fig:ex1} computes $A$ using $B$, while the one of Figure~\ref{fig:ex2} computes $A$ using $C$. Thus, a stencil kernel is defined by a set of input data (in those examples only one input data), and a single output data, the result. The \emph{computation domain} is a subset of elements to compute on the output data. In other words a computation domain is a subset of a mesh entity. For example, in the first stencil kernel, the computation of $A$ is performed on elements represented with full lines, while dotted elements are not computed. On the other hand, on the second kernel, the computation domain of $A$ is exactly equal to the cell mesh entity. The computation domain represents the set of elements on which the kernel is performed, in other words, the space loop.

Finally, a stencil kernel is composed of a \emph{numerical expression} which indicates how to compute an element of the computation domain (on the output data), using elements of the set of input data. The numerical expression of a stencil kernel has the particularity to use not only the element to compute but also a \emph{neighborhood} of this element, also called a \emph{stencil shape}. For example, the stencil shape of the first computation in Figure~\ref{fig:ex1} contains direct neighbors on the right, left, top and bottom. Sometimes, the neighborhood shape can also access a different mesh entity, as for example in Figure~\ref{fig:ex2}. Actually, in this second kernel, the neighborhood contains edges on the left and on the right of a cell. As an example, the numerical expression of the first kernel could be:
\begin{equation*} 
A(x,y) = B(x+1,y)+B(x-1,y)+B(x,y+1)+B(x,y-1),
\end{equation*}
and the numerical expression of the second kernel could be:
\begin{equation*} 
A(x,y) = A(x,y)+C(x1,y1)+C(x1+1,y1).
\end{equation*}

To resume, concepts used in this paper to define a stencil kernel are \emph{mesh}, \emph{mesh entity}, \emph{data}, \emph{computation domain}, \emph{numerical expression} and \emph{stencil shape}. 
If stencil kernels have been studied a lot, the formalization of real overall mesh-based numerical simulations is a rather new contribution. Actually, paying attention to complex numerical simulations, it appears that most of them are composed of more than one stencil kernel, with one or more stencil shapes and of additionnal local computations. For example, we would like to formalize and parallelize a numerical simulation which chains stencil kernels of Figures~\ref{fig:ex1} and~\ref{fig:ex2}. The next section formalize concepts of \emph{stencil kernel}, \emph{local computation} and what we call a \emph{multi-stencil program}.
%\fix{cp2hc: [optionnelle] Par example? domaine applicatif?}

%----------------------------------------
\subsection{A Multi-Stencil Formalization}
\label{sect:multistencil}
%----------------------------------------
Let introduce some formal definitions used in the rest of the paper.
For $\Delta$ the set of data of the simulation, a stencil kernel $s$ is defined as the quintuplet
\begin{equation} 
s(R,w,exp,d),
\label{eq:st}
\end{equation}
where $R$ is a set of pair $(r,n)$, with $r \in \Delta$ is a data read by the computation, and $n$ is a stencil shape (a neighborhood) applied on $r$. The data written by the kernel is denoted $w \in \Delta$, $exp$ is the numerical expression of the stencil kernel. Finally the numerical expression is applied on the computation domain $d$.

For example, in Figure~\ref{fig:ex1}, assuming the computation domain (full lines) is $dc1$ and the stencil shape is $n1$, the stencil kernel can be defined with:
\begin{equation*}
R: {(B,n1)} \quad w: A \quad d: dc1
\end{equation*}
\begin{equation*}
exp: A(x,y)=B(x+1,y)+B(x-1,y)+B(x,y+1)+B(x,y-1).
\end{equation*}
On the other hand, in the example of Figure~\ref{fig:ex2}, assuming the computation domain is $dc2$ and the stencil shape is $n2$, the stencil kernel can be defined with:
\begin{equation*}
R: {(C,n2),(A,null)} \quad w: A \quad d: dc2
\end{equation*}
\begin{equation*}
exp: A(x,y)=A(x,y)+C(x1,y1)+C(x1+1,y1)
\end{equation*}
One can notice that the input data $A$ is associated to the stencil shape $null$. This means that no stencil shape is applied on $A$, but only local accesses.

A local, or auxiliary, computation is a particular case of stencil kernel without neighborhood information in the numerical expression, which makes this kind of computation purely local. A local computation $l$ is defined as the quadruplet:
\begin{equation} 
l(R_l,w,exp,d),
\label{eq:loc}
\end{equation}
where $R_l$ is the set of input data, and other parameters are the same than for a stencil computation.

A multi-stencil program in this work is defined as a sextuplet:
\begin{equation} 
\mathcal{MSP}(T,\mathcal{M},\mathcal{E},\mathcal{D},\Delta,\Gamma),
\label{eq:msp}
\end{equation}
where $T$ is the set of time iteration to run the simulation, $\mathcal{M}$ is the mesh of the simulation, $\mathcal{E}$ is the set of mesh entities, $\mathcal{D}$ is the set of computation domains used into computations, $\Delta$ is the set of data of the simulation, each one mapped onto a mesh entity, and finally $\Gamma$ is the set of computations. The set of computations $\Gamma$ is an ordered list of stencil kernels and local computations. 

\fix{HC 2 all : Est-ce que je laisse cette phrase : One can notice that this work is limited to a single type of mesh in a given simulation.}

% !!!!!!!!!!!! a mettre en plus court autre part !!!!!!!!!!!!!!!
%----------------------------------------
% \subsection{Parallelization techniques}
% \label{sect:parallel}
%----------------------------------------
% Three classical parallelization techniques are used in this paper and are described in this section, the data parallelism, the task parallelism, and the hybrid data and task parallelism. Those parallelization techniques are independent from the actual parallel hardware used.

% \paragraph{Data parallelism} The idea of this parallelization technique is to split, or partition, data on which computations are applied among available processors (or cores). Each processor then applies the same progam or instruction onto its subpart of data. Moreover, if a neighborhood information is needed from another processor communications or synchronizations are performed. 

% In the domain of numerical simulations, this technique is most of the time called a domain decomposition. This parallelization technique produce efficient programs up to thousands processors or cores, but on certain conditions. First, each subpart of data has to be big enough to overlap communication time. Second, the partitioning of data has to be balanced among processors. Thus, if this parallelization technique is clearly adequate to structured meshes, easy to balance, it is not for unstructured meshes or irregular structures where the amount of work is not heterogenous.

% \paragraph{Task parallelism} Another well known parallelization technique is to identify in a program the different tasks and which one are independant and can be launched concurrently. Most of the time, such a prallelization technique create a dependency directed acyclic graph (dependency dag) from a set of ordered tasks. Dependencies are found from read/write information for each task. Actually, if a task $i$ write a data $a$ and if a task $j$ read $a$, then $i$ has to be finished before $j$ is performed. From a dependency graph two different solutions are available. First, a static schedule of tasks is built, which could be a good solution if the tasks are regular, or use a dynamic scheduler to dynamically decide at runtime which task is executed on which processor.

% \paragraph{Hybrid parallelism} Finally, it is also possible to combine both those parallelization techniques to get what is called an hybrid parallelization. The interest of an hybrid parallelization is to bring another source of parallelism if limits of a given technique are reach.

